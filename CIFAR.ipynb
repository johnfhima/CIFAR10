{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4mm9GGiuIpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxnHBAYxHFI5",
        "colab_type": "text"
      },
      "source": [
        "# Import and preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_PRmP28uR8L",
        "colab_type": "code",
        "outputId": "3e71af32-81d5-4de0-b792-5a7e23ae4314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_transforms = transforms.Compose([ #data augmentation and normalization for the training set\n",
        "    transforms.Resize((256)),\n",
        "    transforms.RandomRotation(45),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([#normalisation of the data for the testing set                            \n",
        "    transforms.Resize(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "#downloading the datasets and define the loaders\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
        "                                        download=True, transform=train_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transforms)\n",
        "val_loader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:06, 26295826.76it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWpHYmqGHdOr",
        "colab_type": "text"
      },
      "source": [
        "# Training the model from scratch (with pretrained optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyRLtQ753qhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained = True #put it at false if you don't want a pretrained network\n",
        "number_epoch = 20 #number of epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY7lpSx6uVdW",
        "colab_type": "code",
        "outputId": "e7b8006b-2b52-435d-974d-0fdc5ee91b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#importation of a pretrained resnet152 and change the last fully connected layer to adapt it for the classification\n",
        "model = models.resnet152(pretrained=pretrained)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features,10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n",
            "100%|██████████| 230M/230M [00:01<00:00, 227MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2v3PGxauYCV",
        "colab_type": "code",
        "outputId": "71c33eef-351b-474c-aaf4-30027c4fb737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#We print the model we obtained\n",
        "print(net)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (9): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (10): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (11): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (12): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (13): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (14): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (15): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (16): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (17): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (18): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (19): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (20): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (21): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (22): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (23): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (24): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (25): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (26): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (27): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (28): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (29): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (30): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (31): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (32): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (33): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (34): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (35): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfUCKvHluc2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define an adaptative learning rate which will decrease with the number of epochs\n",
        "def adjust_learning_rate(epoch):\n",
        "    lr = 0.001\n",
        "\n",
        "    if epoch > 100:\n",
        "        return lr / 1000000\n",
        "    elif epoch > 60:\n",
        "        return lr / 100000\n",
        "    elif epoch > 50:\n",
        "        return lr / 10000\n",
        "    elif epoch > 30:\n",
        "        return lr / 1000\n",
        "    elif epoch > 20:\n",
        "        return lr / 100\n",
        "    elif epoch > 10:\n",
        "        return lr / 10\n",
        "    return lr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeZuD0ocueqX",
        "colab_type": "code",
        "outputId": "fd84145d-5e76-4562-db4a-08ca985760ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#boolean to know if gpu is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "# Create experiment folder\n",
        "if not os.path.isdir(\"best_models\"):\n",
        "    os.makedirs(\"best_models\")\n",
        "\n",
        "if use_cuda: #if gpu available, we move the model to gpu\n",
        "    print('Using GPU')\n",
        "    model.cuda()\n",
        "    \n",
        "else:\n",
        "    print('Using CPU')\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #We will use a SGD for optimizer\n",
        "\n",
        "def train(epoch):  #the train for a single epoch\n",
        "    model.train() \n",
        "    for batch_idx, (data, target) in enumerate(train_loader): #for each batch\n",
        "        if use_cuda: #if cuda available, move the data and target to gpu\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        criterion = torch.nn.CrossEntropyLoss(reduction='mean') #We decide to use cross entropy loss for classification\n",
        "        loss = criterion(output, target) #calculate the loss\n",
        "        loss.backward() #do the backpropagation\n",
        "        optimizer.step()\n",
        "        if batch_idx % 50 == 0: #We print the results \n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
        "\n",
        "def validation(): #the evaluation of the test dataset\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in val_loader: #for each data target in the data loader\n",
        "        if use_cuda: #if gpu is available, we move the data and target to gpu\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        output = model(data) \n",
        "        # sum up batch loss\n",
        "        criterion = torch.nn.CrossEntropyLoss(reduction='mean') \n",
        "        validation_loss += criterion(output, target).data.item() #compute the loss\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.data.max(1, keepdim=True)[1] #store the preduction\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum() #add +1 if the prediction is correct otherwise 0\n",
        "\n",
        "    validation_loss /= len(val_loader.dataset) #calculate the loss\n",
        "    #print the loss and the precision of the test set\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        validation_loss, correct, len(val_loader.dataset),\n",
        "        100. * correct / len(val_loader.dataset)))\n",
        "\n",
        "\n",
        "lr = 0.001\n",
        "for epoch in range(1, number_epoch + 1): #for each epoch\n",
        "    optimizer = optim.SGD(model.parameters(), lr, momentum=0.9) #initialise the optimizer \n",
        "    train(epoch) #do the training of the epoch\n",
        "    validation() #and the validation \n",
        "    model_file = 'best_models' + '/model_' + str(epoch) + '.pth' \n",
        "    torch.save(model.state_dict(), model_file) #save the weight of the model\n",
        "    lr = adjust_learning_rate(epoch) #adjust the learning rate\n",
        "    print('Saved model to ' + model_file )\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.247956\n",
            "Train Epoch: 1 [800/50000 (2%)]\tLoss: 1.682932\n",
            "Train Epoch: 1 [1600/50000 (3%)]\tLoss: 1.428827\n",
            "Train Epoch: 1 [2400/50000 (5%)]\tLoss: 0.856192\n",
            "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 0.375466\n",
            "Train Epoch: 1 [4000/50000 (8%)]\tLoss: 0.311743\n",
            "Train Epoch: 1 [4800/50000 (10%)]\tLoss: 0.517842\n",
            "Train Epoch: 1 [5600/50000 (11%)]\tLoss: 0.219456\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 0.377706\n",
            "Train Epoch: 1 [7200/50000 (14%)]\tLoss: 0.476246\n",
            "Train Epoch: 1 [8000/50000 (16%)]\tLoss: 1.186292\n",
            "Train Epoch: 1 [8800/50000 (18%)]\tLoss: 0.325166\n",
            "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 0.481847\n",
            "Train Epoch: 1 [10400/50000 (21%)]\tLoss: 0.358318\n",
            "Train Epoch: 1 [11200/50000 (22%)]\tLoss: 0.303598\n",
            "Train Epoch: 1 [12000/50000 (24%)]\tLoss: 0.240508\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.582469\n",
            "Train Epoch: 1 [13600/50000 (27%)]\tLoss: 0.846305\n",
            "Train Epoch: 1 [14400/50000 (29%)]\tLoss: 0.623094\n",
            "Train Epoch: 1 [15200/50000 (30%)]\tLoss: 0.388029\n",
            "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.262860\n",
            "Train Epoch: 1 [16800/50000 (34%)]\tLoss: 0.613581\n",
            "Train Epoch: 1 [17600/50000 (35%)]\tLoss: 0.089800\n",
            "Train Epoch: 1 [18400/50000 (37%)]\tLoss: 0.419863\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.379857\n",
            "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 0.452790\n",
            "Train Epoch: 1 [20800/50000 (42%)]\tLoss: 0.095633\n",
            "Train Epoch: 1 [21600/50000 (43%)]\tLoss: 0.185837\n",
            "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 0.332274\n",
            "Train Epoch: 1 [23200/50000 (46%)]\tLoss: 0.903857\n",
            "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 0.197837\n",
            "Train Epoch: 1 [24800/50000 (50%)]\tLoss: 0.523607\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.142591\n",
            "Train Epoch: 1 [26400/50000 (53%)]\tLoss: 0.133025\n",
            "Train Epoch: 1 [27200/50000 (54%)]\tLoss: 0.306159\n",
            "Train Epoch: 1 [28000/50000 (56%)]\tLoss: 0.203366\n",
            "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 0.179428\n",
            "Train Epoch: 1 [29600/50000 (59%)]\tLoss: 0.422458\n",
            "Train Epoch: 1 [30400/50000 (61%)]\tLoss: 0.113670\n",
            "Train Epoch: 1 [31200/50000 (62%)]\tLoss: 0.251975\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.170173\n",
            "Train Epoch: 1 [32800/50000 (66%)]\tLoss: 0.571000\n",
            "Train Epoch: 1 [33600/50000 (67%)]\tLoss: 0.163217\n",
            "Train Epoch: 1 [34400/50000 (69%)]\tLoss: 0.253197\n",
            "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 0.221123\n",
            "Train Epoch: 1 [36000/50000 (72%)]\tLoss: 0.373469\n",
            "Train Epoch: 1 [36800/50000 (74%)]\tLoss: 0.447712\n",
            "Train Epoch: 1 [37600/50000 (75%)]\tLoss: 0.173586\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.145342\n",
            "Train Epoch: 1 [39200/50000 (78%)]\tLoss: 0.077301\n",
            "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 0.487299\n",
            "Train Epoch: 1 [40800/50000 (82%)]\tLoss: 0.677444\n",
            "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.035078\n",
            "Train Epoch: 1 [42400/50000 (85%)]\tLoss: 0.461004\n",
            "Train Epoch: 1 [43200/50000 (86%)]\tLoss: 0.771310\n",
            "Train Epoch: 1 [44000/50000 (88%)]\tLoss: 0.084547\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.293271\n",
            "Train Epoch: 1 [45600/50000 (91%)]\tLoss: 0.399927\n",
            "Train Epoch: 1 [46400/50000 (93%)]\tLoss: 0.401592\n",
            "Train Epoch: 1 [47200/50000 (94%)]\tLoss: 0.332873\n",
            "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.133308\n",
            "Train Epoch: 1 [48800/50000 (98%)]\tLoss: 0.117271\n",
            "Train Epoch: 1 [49600/50000 (99%)]\tLoss: 0.200832\n",
            "\n",
            "Validation set: Average loss: 0.0106, Accuracy: 9436/10000 (94%)\n",
            "Saved model to best_models/model_1.pth\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.344033\n",
            "Train Epoch: 2 [800/50000 (2%)]\tLoss: 0.452767\n",
            "Train Epoch: 2 [1600/50000 (3%)]\tLoss: 0.130073\n",
            "Train Epoch: 2 [2400/50000 (5%)]\tLoss: 0.073965\n",
            "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 0.415436\n",
            "Train Epoch: 2 [4000/50000 (8%)]\tLoss: 0.073313\n",
            "Train Epoch: 2 [4800/50000 (10%)]\tLoss: 0.183209\n",
            "Train Epoch: 2 [5600/50000 (11%)]\tLoss: 0.175045\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.196837\n",
            "Train Epoch: 2 [7200/50000 (14%)]\tLoss: 0.384030\n",
            "Train Epoch: 2 [8000/50000 (16%)]\tLoss: 0.135180\n",
            "Train Epoch: 2 [8800/50000 (18%)]\tLoss: 0.114288\n",
            "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 0.147102\n",
            "Train Epoch: 2 [10400/50000 (21%)]\tLoss: 0.026005\n",
            "Train Epoch: 2 [11200/50000 (22%)]\tLoss: 0.431807\n",
            "Train Epoch: 2 [12000/50000 (24%)]\tLoss: 0.312633\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.188064\n",
            "Train Epoch: 2 [13600/50000 (27%)]\tLoss: 0.131500\n",
            "Train Epoch: 2 [14400/50000 (29%)]\tLoss: 0.143046\n",
            "Train Epoch: 2 [15200/50000 (30%)]\tLoss: 0.578360\n",
            "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.104758\n",
            "Train Epoch: 2 [16800/50000 (34%)]\tLoss: 0.052112\n",
            "Train Epoch: 2 [17600/50000 (35%)]\tLoss: 0.056267\n",
            "Train Epoch: 2 [18400/50000 (37%)]\tLoss: 0.140830\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.253112\n",
            "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 0.023797\n",
            "Train Epoch: 2 [20800/50000 (42%)]\tLoss: 0.093769\n",
            "Train Epoch: 2 [21600/50000 (43%)]\tLoss: 0.269196\n",
            "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.241639\n",
            "Train Epoch: 2 [23200/50000 (46%)]\tLoss: 0.056498\n",
            "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 0.390819\n",
            "Train Epoch: 2 [24800/50000 (50%)]\tLoss: 0.092217\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.236286\n",
            "Train Epoch: 2 [26400/50000 (53%)]\tLoss: 0.084382\n",
            "Train Epoch: 2 [27200/50000 (54%)]\tLoss: 0.258031\n",
            "Train Epoch: 2 [28000/50000 (56%)]\tLoss: 0.298136\n",
            "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.041692\n",
            "Train Epoch: 2 [29600/50000 (59%)]\tLoss: 0.418527\n",
            "Train Epoch: 2 [30400/50000 (61%)]\tLoss: 0.086707\n",
            "Train Epoch: 2 [31200/50000 (62%)]\tLoss: 0.197037\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.061714\n",
            "Train Epoch: 2 [32800/50000 (66%)]\tLoss: 0.189032\n",
            "Train Epoch: 2 [33600/50000 (67%)]\tLoss: 0.075133\n",
            "Train Epoch: 2 [34400/50000 (69%)]\tLoss: 0.062817\n",
            "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.102269\n",
            "Train Epoch: 2 [36000/50000 (72%)]\tLoss: 0.072222\n",
            "Train Epoch: 2 [36800/50000 (74%)]\tLoss: 0.139107\n",
            "Train Epoch: 2 [37600/50000 (75%)]\tLoss: 0.293413\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.139014\n",
            "Train Epoch: 2 [39200/50000 (78%)]\tLoss: 0.022520\n",
            "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 0.344983\n",
            "Train Epoch: 2 [40800/50000 (82%)]\tLoss: 0.167304\n",
            "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.093746\n",
            "Train Epoch: 2 [42400/50000 (85%)]\tLoss: 0.022033\n",
            "Train Epoch: 2 [43200/50000 (86%)]\tLoss: 0.067141\n",
            "Train Epoch: 2 [44000/50000 (88%)]\tLoss: 0.043219\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.351322\n",
            "Train Epoch: 2 [45600/50000 (91%)]\tLoss: 0.126877\n",
            "Train Epoch: 2 [46400/50000 (93%)]\tLoss: 0.629571\n",
            "Train Epoch: 2 [47200/50000 (94%)]\tLoss: 0.380715\n",
            "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.020144\n",
            "Train Epoch: 2 [48800/50000 (98%)]\tLoss: 0.116954\n",
            "Train Epoch: 2 [49600/50000 (99%)]\tLoss: 0.045506\n",
            "\n",
            "Validation set: Average loss: 0.0071, Accuracy: 9619/10000 (96%)\n",
            "Saved model to best_models/model_2.pth\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.173288\n",
            "Train Epoch: 3 [800/50000 (2%)]\tLoss: 0.044969\n",
            "Train Epoch: 3 [1600/50000 (3%)]\tLoss: 0.016650\n",
            "Train Epoch: 3 [2400/50000 (5%)]\tLoss: 0.523906\n",
            "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.488793\n",
            "Train Epoch: 3 [4000/50000 (8%)]\tLoss: 0.028938\n",
            "Train Epoch: 3 [4800/50000 (10%)]\tLoss: 0.436811\n",
            "Train Epoch: 3 [5600/50000 (11%)]\tLoss: 0.225217\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.067508\n",
            "Train Epoch: 3 [7200/50000 (14%)]\tLoss: 0.135250\n",
            "Train Epoch: 3 [8000/50000 (16%)]\tLoss: 0.208268\n",
            "Train Epoch: 3 [8800/50000 (18%)]\tLoss: 0.135599\n",
            "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.371025\n",
            "Train Epoch: 3 [10400/50000 (21%)]\tLoss: 0.129578\n",
            "Train Epoch: 3 [11200/50000 (22%)]\tLoss: 0.203068\n",
            "Train Epoch: 3 [12000/50000 (24%)]\tLoss: 0.063528\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.291393\n",
            "Train Epoch: 3 [13600/50000 (27%)]\tLoss: 0.152568\n",
            "Train Epoch: 3 [14400/50000 (29%)]\tLoss: 0.250816\n",
            "Train Epoch: 3 [15200/50000 (30%)]\tLoss: 0.099375\n",
            "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.563916\n",
            "Train Epoch: 3 [16800/50000 (34%)]\tLoss: 0.505315\n",
            "Train Epoch: 3 [17600/50000 (35%)]\tLoss: 0.091775\n",
            "Train Epoch: 3 [18400/50000 (37%)]\tLoss: 0.028352\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.106523\n",
            "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 0.009676\n",
            "Train Epoch: 3 [20800/50000 (42%)]\tLoss: 0.340334\n",
            "Train Epoch: 3 [21600/50000 (43%)]\tLoss: 0.172458\n",
            "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.006308\n",
            "Train Epoch: 3 [23200/50000 (46%)]\tLoss: 0.006270\n",
            "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 0.143339\n",
            "Train Epoch: 3 [24800/50000 (50%)]\tLoss: 0.213453\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.082023\n",
            "Train Epoch: 3 [26400/50000 (53%)]\tLoss: 0.035804\n",
            "Train Epoch: 3 [27200/50000 (54%)]\tLoss: 0.085695\n",
            "Train Epoch: 3 [28000/50000 (56%)]\tLoss: 0.070597\n",
            "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.139227\n",
            "Train Epoch: 3 [29600/50000 (59%)]\tLoss: 0.045345\n",
            "Train Epoch: 3 [30400/50000 (61%)]\tLoss: 0.304784\n",
            "Train Epoch: 3 [31200/50000 (62%)]\tLoss: 0.180004\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.213662\n",
            "Train Epoch: 3 [32800/50000 (66%)]\tLoss: 0.166525\n",
            "Train Epoch: 3 [33600/50000 (67%)]\tLoss: 0.089794\n",
            "Train Epoch: 3 [34400/50000 (69%)]\tLoss: 0.200363\n",
            "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.048642\n",
            "Train Epoch: 3 [36000/50000 (72%)]\tLoss: 0.008726\n",
            "Train Epoch: 3 [36800/50000 (74%)]\tLoss: 0.031280\n",
            "Train Epoch: 3 [37600/50000 (75%)]\tLoss: 0.204481\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.157381\n",
            "Train Epoch: 3 [39200/50000 (78%)]\tLoss: 0.077891\n",
            "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 0.018687\n",
            "Train Epoch: 3 [40800/50000 (82%)]\tLoss: 0.089397\n",
            "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.250748\n",
            "Train Epoch: 3 [42400/50000 (85%)]\tLoss: 0.101203\n",
            "Train Epoch: 3 [43200/50000 (86%)]\tLoss: 0.176277\n",
            "Train Epoch: 3 [44000/50000 (88%)]\tLoss: 0.103726\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.023742\n",
            "Train Epoch: 3 [45600/50000 (91%)]\tLoss: 0.152134\n",
            "Train Epoch: 3 [46400/50000 (93%)]\tLoss: 0.112366\n",
            "Train Epoch: 3 [47200/50000 (94%)]\tLoss: 0.019429\n",
            "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.219054\n",
            "Train Epoch: 3 [48800/50000 (98%)]\tLoss: 0.030678\n",
            "Train Epoch: 3 [49600/50000 (99%)]\tLoss: 0.346642\n",
            "\n",
            "Validation set: Average loss: 0.0082, Accuracy: 9566/10000 (96%)\n",
            "Saved model to best_models/model_3.pth\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.022155\n",
            "Train Epoch: 4 [800/50000 (2%)]\tLoss: 0.131947\n",
            "Train Epoch: 4 [1600/50000 (3%)]\tLoss: 0.016800\n",
            "Train Epoch: 4 [2400/50000 (5%)]\tLoss: 0.108258\n",
            "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 0.008404\n",
            "Train Epoch: 4 [4000/50000 (8%)]\tLoss: 0.013221\n",
            "Train Epoch: 4 [4800/50000 (10%)]\tLoss: 0.045037\n",
            "Train Epoch: 4 [5600/50000 (11%)]\tLoss: 0.036906\n",
            "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.027483\n",
            "Train Epoch: 4 [7200/50000 (14%)]\tLoss: 0.105482\n",
            "Train Epoch: 4 [8000/50000 (16%)]\tLoss: 0.095476\n",
            "Train Epoch: 4 [8800/50000 (18%)]\tLoss: 0.042738\n",
            "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 0.037173\n",
            "Train Epoch: 4 [10400/50000 (21%)]\tLoss: 0.197442\n",
            "Train Epoch: 4 [11200/50000 (22%)]\tLoss: 0.146395\n",
            "Train Epoch: 4 [12000/50000 (24%)]\tLoss: 0.533300\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.006781\n",
            "Train Epoch: 4 [13600/50000 (27%)]\tLoss: 0.028077\n",
            "Train Epoch: 4 [14400/50000 (29%)]\tLoss: 0.012430\n",
            "Train Epoch: 4 [15200/50000 (30%)]\tLoss: 0.036299\n",
            "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.118807\n",
            "Train Epoch: 4 [16800/50000 (34%)]\tLoss: 0.086029\n",
            "Train Epoch: 4 [17600/50000 (35%)]\tLoss: 0.025217\n",
            "Train Epoch: 4 [18400/50000 (37%)]\tLoss: 0.108831\n",
            "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.038760\n",
            "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 0.019382\n",
            "Train Epoch: 4 [20800/50000 (42%)]\tLoss: 0.146548\n",
            "Train Epoch: 4 [21600/50000 (43%)]\tLoss: 0.036350\n",
            "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 0.079722\n",
            "Train Epoch: 4 [23200/50000 (46%)]\tLoss: 0.003793\n",
            "Train Epoch: 4 [24000/50000 (48%)]\tLoss: 0.013714\n",
            "Train Epoch: 4 [24800/50000 (50%)]\tLoss: 0.040689\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.237560\n",
            "Train Epoch: 4 [26400/50000 (53%)]\tLoss: 0.337809\n",
            "Train Epoch: 4 [27200/50000 (54%)]\tLoss: 0.019380\n",
            "Train Epoch: 4 [28000/50000 (56%)]\tLoss: 0.074716\n",
            "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 0.030918\n",
            "Train Epoch: 4 [29600/50000 (59%)]\tLoss: 0.038158\n",
            "Train Epoch: 4 [30400/50000 (61%)]\tLoss: 0.409845\n",
            "Train Epoch: 4 [31200/50000 (62%)]\tLoss: 0.029545\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.170133\n",
            "Train Epoch: 4 [32800/50000 (66%)]\tLoss: 0.011374\n",
            "Train Epoch: 4 [33600/50000 (67%)]\tLoss: 0.048730\n",
            "Train Epoch: 4 [34400/50000 (69%)]\tLoss: 0.042454\n",
            "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 0.260212\n",
            "Train Epoch: 4 [36000/50000 (72%)]\tLoss: 0.032278\n",
            "Train Epoch: 4 [36800/50000 (74%)]\tLoss: 0.183547\n",
            "Train Epoch: 4 [37600/50000 (75%)]\tLoss: 0.120947\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.029639\n",
            "Train Epoch: 4 [39200/50000 (78%)]\tLoss: 0.025831\n",
            "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 0.012728\n",
            "Train Epoch: 4 [40800/50000 (82%)]\tLoss: 0.032598\n",
            "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 0.313437\n",
            "Train Epoch: 4 [42400/50000 (85%)]\tLoss: 0.057784\n",
            "Train Epoch: 4 [43200/50000 (86%)]\tLoss: 0.360727\n",
            "Train Epoch: 4 [44000/50000 (88%)]\tLoss: 0.064612\n",
            "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.264661\n",
            "Train Epoch: 4 [45600/50000 (91%)]\tLoss: 0.040627\n",
            "Train Epoch: 4 [46400/50000 (93%)]\tLoss: 0.163299\n",
            "Train Epoch: 4 [47200/50000 (94%)]\tLoss: 0.229846\n",
            "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.054923\n",
            "Train Epoch: 4 [48800/50000 (98%)]\tLoss: 0.006015\n",
            "Train Epoch: 4 [49600/50000 (99%)]\tLoss: 0.148835\n",
            "\n",
            "Validation set: Average loss: 0.0061, Accuracy: 9688/10000 (97%)\n",
            "Saved model to best_models/model_4.pth\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.073199\n",
            "Train Epoch: 5 [800/50000 (2%)]\tLoss: 0.050886\n",
            "Train Epoch: 5 [1600/50000 (3%)]\tLoss: 0.125404\n",
            "Train Epoch: 5 [2400/50000 (5%)]\tLoss: 0.015860\n",
            "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 0.023809\n",
            "Train Epoch: 5 [4000/50000 (8%)]\tLoss: 0.221671\n",
            "Train Epoch: 5 [4800/50000 (10%)]\tLoss: 0.106711\n",
            "Train Epoch: 5 [5600/50000 (11%)]\tLoss: 0.036297\n",
            "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.139797\n",
            "Train Epoch: 5 [7200/50000 (14%)]\tLoss: 0.868954\n",
            "Train Epoch: 5 [8000/50000 (16%)]\tLoss: 0.028061\n",
            "Train Epoch: 5 [8800/50000 (18%)]\tLoss: 0.054901\n",
            "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 0.014114\n",
            "Train Epoch: 5 [10400/50000 (21%)]\tLoss: 0.025178\n",
            "Train Epoch: 5 [11200/50000 (22%)]\tLoss: 0.127167\n",
            "Train Epoch: 5 [12000/50000 (24%)]\tLoss: 0.005338\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.198306\n",
            "Train Epoch: 5 [13600/50000 (27%)]\tLoss: 0.005886\n",
            "Train Epoch: 5 [14400/50000 (29%)]\tLoss: 0.197258\n",
            "Train Epoch: 5 [15200/50000 (30%)]\tLoss: 0.210920\n",
            "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.002249\n",
            "Train Epoch: 5 [16800/50000 (34%)]\tLoss: 0.056539\n",
            "Train Epoch: 5 [17600/50000 (35%)]\tLoss: 0.239317\n",
            "Train Epoch: 5 [18400/50000 (37%)]\tLoss: 0.229242\n",
            "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.017188\n",
            "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 0.020159\n",
            "Train Epoch: 5 [20800/50000 (42%)]\tLoss: 0.016789\n",
            "Train Epoch: 5 [21600/50000 (43%)]\tLoss: 0.121557\n",
            "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 0.245460\n",
            "Train Epoch: 5 [23200/50000 (46%)]\tLoss: 0.301219\n",
            "Train Epoch: 5 [24000/50000 (48%)]\tLoss: 0.001216\n",
            "Train Epoch: 5 [24800/50000 (50%)]\tLoss: 0.150337\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.058546\n",
            "Train Epoch: 5 [26400/50000 (53%)]\tLoss: 0.152501\n",
            "Train Epoch: 5 [27200/50000 (54%)]\tLoss: 0.018623\n",
            "Train Epoch: 5 [28000/50000 (56%)]\tLoss: 0.020778\n",
            "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 0.059357\n",
            "Train Epoch: 5 [29600/50000 (59%)]\tLoss: 0.187583\n",
            "Train Epoch: 5 [30400/50000 (61%)]\tLoss: 0.019335\n",
            "Train Epoch: 5 [31200/50000 (62%)]\tLoss: 0.333444\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.146953\n",
            "Train Epoch: 5 [32800/50000 (66%)]\tLoss: 0.033388\n",
            "Train Epoch: 5 [33600/50000 (67%)]\tLoss: 0.106860\n",
            "Train Epoch: 5 [34400/50000 (69%)]\tLoss: 0.066138\n",
            "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 0.072344\n",
            "Train Epoch: 5 [36000/50000 (72%)]\tLoss: 0.122887\n",
            "Train Epoch: 5 [36800/50000 (74%)]\tLoss: 0.115408\n",
            "Train Epoch: 5 [37600/50000 (75%)]\tLoss: 0.066649\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.036403\n",
            "Train Epoch: 5 [39200/50000 (78%)]\tLoss: 0.048405\n",
            "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 0.180143\n",
            "Train Epoch: 5 [40800/50000 (82%)]\tLoss: 0.076748\n",
            "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 0.111689\n",
            "Train Epoch: 5 [42400/50000 (85%)]\tLoss: 0.019514\n",
            "Train Epoch: 5 [43200/50000 (86%)]\tLoss: 0.029544\n",
            "Train Epoch: 5 [44000/50000 (88%)]\tLoss: 0.003980\n",
            "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.004981\n",
            "Train Epoch: 5 [45600/50000 (91%)]\tLoss: 0.349894\n",
            "Train Epoch: 5 [46400/50000 (93%)]\tLoss: 0.035571\n",
            "Train Epoch: 5 [47200/50000 (94%)]\tLoss: 0.002863\n",
            "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.011434\n",
            "Train Epoch: 5 [48800/50000 (98%)]\tLoss: 0.364607\n",
            "Train Epoch: 5 [49600/50000 (99%)]\tLoss: 0.057260\n",
            "\n",
            "Validation set: Average loss: 0.0067, Accuracy: 9664/10000 (97%)\n",
            "Saved model to best_models/model_5.pth\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.096658\n",
            "Train Epoch: 6 [800/50000 (2%)]\tLoss: 0.018222\n",
            "Train Epoch: 6 [1600/50000 (3%)]\tLoss: 0.010072\n",
            "Train Epoch: 6 [2400/50000 (5%)]\tLoss: 0.094475\n",
            "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 0.193674\n",
            "Train Epoch: 6 [4000/50000 (8%)]\tLoss: 0.002621\n",
            "Train Epoch: 6 [4800/50000 (10%)]\tLoss: 0.010987\n",
            "Train Epoch: 6 [5600/50000 (11%)]\tLoss: 0.035440\n",
            "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.009568\n",
            "Train Epoch: 6 [7200/50000 (14%)]\tLoss: 0.091815\n",
            "Train Epoch: 6 [8000/50000 (16%)]\tLoss: 0.004399\n",
            "Train Epoch: 6 [8800/50000 (18%)]\tLoss: 0.007049\n",
            "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 0.022998\n",
            "Train Epoch: 6 [10400/50000 (21%)]\tLoss: 0.134726\n",
            "Train Epoch: 6 [11200/50000 (22%)]\tLoss: 0.037673\n",
            "Train Epoch: 6 [12000/50000 (24%)]\tLoss: 0.005144\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.026402\n",
            "Train Epoch: 6 [13600/50000 (27%)]\tLoss: 0.139396\n",
            "Train Epoch: 6 [14400/50000 (29%)]\tLoss: 0.031980\n",
            "Train Epoch: 6 [15200/50000 (30%)]\tLoss: 0.404039\n",
            "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.084348\n",
            "Train Epoch: 6 [16800/50000 (34%)]\tLoss: 0.217007\n",
            "Train Epoch: 6 [17600/50000 (35%)]\tLoss: 0.062539\n",
            "Train Epoch: 6 [18400/50000 (37%)]\tLoss: 0.124304\n",
            "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.160251\n",
            "Train Epoch: 6 [20000/50000 (40%)]\tLoss: 0.260993\n",
            "Train Epoch: 6 [20800/50000 (42%)]\tLoss: 0.008584\n",
            "Train Epoch: 6 [21600/50000 (43%)]\tLoss: 0.119367\n",
            "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 0.316185\n",
            "Train Epoch: 6 [23200/50000 (46%)]\tLoss: 0.162878\n",
            "Train Epoch: 6 [24000/50000 (48%)]\tLoss: 0.028961\n",
            "Train Epoch: 6 [24800/50000 (50%)]\tLoss: 0.070378\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.002205\n",
            "Train Epoch: 6 [26400/50000 (53%)]\tLoss: 0.011620\n",
            "Train Epoch: 6 [27200/50000 (54%)]\tLoss: 0.097715\n",
            "Train Epoch: 6 [28000/50000 (56%)]\tLoss: 0.023623\n",
            "Train Epoch: 6 [28800/50000 (58%)]\tLoss: 0.734869\n",
            "Train Epoch: 6 [29600/50000 (59%)]\tLoss: 0.219097\n",
            "Train Epoch: 6 [30400/50000 (61%)]\tLoss: 0.138198\n",
            "Train Epoch: 6 [31200/50000 (62%)]\tLoss: 0.087811\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.004398\n",
            "Train Epoch: 6 [32800/50000 (66%)]\tLoss: 0.126041\n",
            "Train Epoch: 6 [33600/50000 (67%)]\tLoss: 0.273050\n",
            "Train Epoch: 6 [34400/50000 (69%)]\tLoss: 0.002177\n",
            "Train Epoch: 6 [35200/50000 (70%)]\tLoss: 0.013707\n",
            "Train Epoch: 6 [36000/50000 (72%)]\tLoss: 0.031193\n",
            "Train Epoch: 6 [36800/50000 (74%)]\tLoss: 0.052633\n",
            "Train Epoch: 6 [37600/50000 (75%)]\tLoss: 0.133564\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.008605\n",
            "Train Epoch: 6 [39200/50000 (78%)]\tLoss: 0.071219\n",
            "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 0.024519\n",
            "Train Epoch: 6 [40800/50000 (82%)]\tLoss: 0.518219\n",
            "Train Epoch: 6 [41600/50000 (83%)]\tLoss: 0.017772\n",
            "Train Epoch: 6 [42400/50000 (85%)]\tLoss: 0.166982\n",
            "Train Epoch: 6 [43200/50000 (86%)]\tLoss: 0.030858\n",
            "Train Epoch: 6 [44000/50000 (88%)]\tLoss: 0.186725\n",
            "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.010034\n",
            "Train Epoch: 6 [45600/50000 (91%)]\tLoss: 0.013420\n",
            "Train Epoch: 6 [46400/50000 (93%)]\tLoss: 0.091098\n",
            "Train Epoch: 6 [47200/50000 (94%)]\tLoss: 0.414681\n",
            "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.005178\n",
            "Train Epoch: 6 [48800/50000 (98%)]\tLoss: 0.057936\n",
            "Train Epoch: 6 [49600/50000 (99%)]\tLoss: 0.039505\n",
            "\n",
            "Validation set: Average loss: 0.0066, Accuracy: 9648/10000 (96%)\n",
            "Saved model to best_models/model_6.pth\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.041974\n",
            "Train Epoch: 7 [800/50000 (2%)]\tLoss: 0.273380\n",
            "Train Epoch: 7 [1600/50000 (3%)]\tLoss: 0.296450\n",
            "Train Epoch: 7 [2400/50000 (5%)]\tLoss: 0.224363\n",
            "Train Epoch: 7 [3200/50000 (6%)]\tLoss: 0.016994\n",
            "Train Epoch: 7 [4000/50000 (8%)]\tLoss: 0.003178\n",
            "Train Epoch: 7 [4800/50000 (10%)]\tLoss: 0.093690\n",
            "Train Epoch: 7 [5600/50000 (11%)]\tLoss: 0.026102\n",
            "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.006208\n",
            "Train Epoch: 7 [7200/50000 (14%)]\tLoss: 0.002812\n",
            "Train Epoch: 7 [8000/50000 (16%)]\tLoss: 0.007310\n",
            "Train Epoch: 7 [8800/50000 (18%)]\tLoss: 0.004635\n",
            "Train Epoch: 7 [9600/50000 (19%)]\tLoss: 0.084370\n",
            "Train Epoch: 7 [10400/50000 (21%)]\tLoss: 0.009608\n",
            "Train Epoch: 7 [11200/50000 (22%)]\tLoss: 0.002167\n",
            "Train Epoch: 7 [12000/50000 (24%)]\tLoss: 0.001518\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.123436\n",
            "Train Epoch: 7 [13600/50000 (27%)]\tLoss: 0.023740\n",
            "Train Epoch: 7 [14400/50000 (29%)]\tLoss: 0.018373\n",
            "Train Epoch: 7 [15200/50000 (30%)]\tLoss: 0.044563\n",
            "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.019424\n",
            "Train Epoch: 7 [16800/50000 (34%)]\tLoss: 0.002050\n",
            "Train Epoch: 7 [17600/50000 (35%)]\tLoss: 0.008691\n",
            "Train Epoch: 7 [18400/50000 (37%)]\tLoss: 0.010982\n",
            "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.037763\n",
            "Train Epoch: 7 [20000/50000 (40%)]\tLoss: 0.029007\n",
            "Train Epoch: 7 [20800/50000 (42%)]\tLoss: 0.043379\n",
            "Train Epoch: 7 [21600/50000 (43%)]\tLoss: 0.004092\n",
            "Train Epoch: 7 [22400/50000 (45%)]\tLoss: 0.005920\n",
            "Train Epoch: 7 [23200/50000 (46%)]\tLoss: 0.069132\n",
            "Train Epoch: 7 [24000/50000 (48%)]\tLoss: 0.009401\n",
            "Train Epoch: 7 [24800/50000 (50%)]\tLoss: 0.202591\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.034555\n",
            "Train Epoch: 7 [26400/50000 (53%)]\tLoss: 0.004169\n",
            "Train Epoch: 7 [27200/50000 (54%)]\tLoss: 0.247831\n",
            "Train Epoch: 7 [28000/50000 (56%)]\tLoss: 0.003269\n",
            "Train Epoch: 7 [28800/50000 (58%)]\tLoss: 0.004508\n",
            "Train Epoch: 7 [29600/50000 (59%)]\tLoss: 0.054795\n",
            "Train Epoch: 7 [30400/50000 (61%)]\tLoss: 0.066884\n",
            "Train Epoch: 7 [31200/50000 (62%)]\tLoss: 0.032781\n",
            "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.310649\n",
            "Train Epoch: 7 [32800/50000 (66%)]\tLoss: 0.121762\n",
            "Train Epoch: 7 [33600/50000 (67%)]\tLoss: 0.030602\n",
            "Train Epoch: 7 [34400/50000 (69%)]\tLoss: 0.024722\n",
            "Train Epoch: 7 [35200/50000 (70%)]\tLoss: 0.004935\n",
            "Train Epoch: 7 [36000/50000 (72%)]\tLoss: 0.001704\n",
            "Train Epoch: 7 [36800/50000 (74%)]\tLoss: 0.058303\n",
            "Train Epoch: 7 [37600/50000 (75%)]\tLoss: 0.126395\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.166993\n",
            "Train Epoch: 7 [39200/50000 (78%)]\tLoss: 0.020684\n",
            "Train Epoch: 7 [40000/50000 (80%)]\tLoss: 0.068686\n",
            "Train Epoch: 7 [40800/50000 (82%)]\tLoss: 0.075170\n",
            "Train Epoch: 7 [41600/50000 (83%)]\tLoss: 0.082927\n",
            "Train Epoch: 7 [42400/50000 (85%)]\tLoss: 0.020705\n",
            "Train Epoch: 7 [43200/50000 (86%)]\tLoss: 0.003359\n",
            "Train Epoch: 7 [44000/50000 (88%)]\tLoss: 0.001324\n",
            "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.003140\n",
            "Train Epoch: 7 [45600/50000 (91%)]\tLoss: 0.021735\n",
            "Train Epoch: 7 [46400/50000 (93%)]\tLoss: 0.088192\n",
            "Train Epoch: 7 [47200/50000 (94%)]\tLoss: 0.058190\n",
            "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.000922\n",
            "Train Epoch: 7 [48800/50000 (98%)]\tLoss: 0.005239\n",
            "Train Epoch: 7 [49600/50000 (99%)]\tLoss: 0.368053\n",
            "\n",
            "Validation set: Average loss: 0.0072, Accuracy: 9646/10000 (96%)\n",
            "Saved model to best_models/model_7.pth\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.067254\n",
            "Train Epoch: 8 [800/50000 (2%)]\tLoss: 0.066672\n",
            "Train Epoch: 8 [1600/50000 (3%)]\tLoss: 0.007533\n",
            "Train Epoch: 8 [2400/50000 (5%)]\tLoss: 0.027916\n",
            "Train Epoch: 8 [3200/50000 (6%)]\tLoss: 0.016806\n",
            "Train Epoch: 8 [4000/50000 (8%)]\tLoss: 0.228082\n",
            "Train Epoch: 8 [4800/50000 (10%)]\tLoss: 0.017505\n",
            "Train Epoch: 8 [5600/50000 (11%)]\tLoss: 0.206416\n",
            "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.612078\n",
            "Train Epoch: 8 [7200/50000 (14%)]\tLoss: 0.018284\n",
            "Train Epoch: 8 [8000/50000 (16%)]\tLoss: 0.000997\n",
            "Train Epoch: 8 [8800/50000 (18%)]\tLoss: 0.104006\n",
            "Train Epoch: 8 [9600/50000 (19%)]\tLoss: 0.022570\n",
            "Train Epoch: 8 [10400/50000 (21%)]\tLoss: 0.009513\n",
            "Train Epoch: 8 [11200/50000 (22%)]\tLoss: 0.071370\n",
            "Train Epoch: 8 [12000/50000 (24%)]\tLoss: 0.137068\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.002206\n",
            "Train Epoch: 8 [13600/50000 (27%)]\tLoss: 0.032051\n",
            "Train Epoch: 8 [14400/50000 (29%)]\tLoss: 0.055604\n",
            "Train Epoch: 8 [15200/50000 (30%)]\tLoss: 0.010641\n",
            "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.076679\n",
            "Train Epoch: 8 [16800/50000 (34%)]\tLoss: 0.059401\n",
            "Train Epoch: 8 [17600/50000 (35%)]\tLoss: 0.071054\n",
            "Train Epoch: 8 [18400/50000 (37%)]\tLoss: 0.021605\n",
            "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.051155\n",
            "Train Epoch: 8 [20000/50000 (40%)]\tLoss: 0.000681\n",
            "Train Epoch: 8 [20800/50000 (42%)]\tLoss: 0.026892\n",
            "Train Epoch: 8 [21600/50000 (43%)]\tLoss: 0.003000\n",
            "Train Epoch: 8 [22400/50000 (45%)]\tLoss: 0.009116\n",
            "Train Epoch: 8 [23200/50000 (46%)]\tLoss: 0.003178\n",
            "Train Epoch: 8 [24000/50000 (48%)]\tLoss: 0.018371\n",
            "Train Epoch: 8 [24800/50000 (50%)]\tLoss: 0.018162\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.022900\n",
            "Train Epoch: 8 [26400/50000 (53%)]\tLoss: 0.020428\n",
            "Train Epoch: 8 [27200/50000 (54%)]\tLoss: 0.045483\n",
            "Train Epoch: 8 [28000/50000 (56%)]\tLoss: 0.171363\n",
            "Train Epoch: 8 [28800/50000 (58%)]\tLoss: 0.000540\n",
            "Train Epoch: 8 [29600/50000 (59%)]\tLoss: 0.001520\n",
            "Train Epoch: 8 [30400/50000 (61%)]\tLoss: 0.001493\n",
            "Train Epoch: 8 [31200/50000 (62%)]\tLoss: 0.042232\n",
            "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.028306\n",
            "Train Epoch: 8 [32800/50000 (66%)]\tLoss: 0.023754\n",
            "Train Epoch: 8 [33600/50000 (67%)]\tLoss: 0.071524\n",
            "Train Epoch: 8 [34400/50000 (69%)]\tLoss: 0.003602\n",
            "Train Epoch: 8 [35200/50000 (70%)]\tLoss: 0.045917\n",
            "Train Epoch: 8 [36000/50000 (72%)]\tLoss: 0.223054\n",
            "Train Epoch: 8 [36800/50000 (74%)]\tLoss: 0.037100\n",
            "Train Epoch: 8 [37600/50000 (75%)]\tLoss: 0.003870\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.020812\n",
            "Train Epoch: 8 [39200/50000 (78%)]\tLoss: 0.007809\n",
            "Train Epoch: 8 [40000/50000 (80%)]\tLoss: 0.066783\n",
            "Train Epoch: 8 [40800/50000 (82%)]\tLoss: 0.003747\n",
            "Train Epoch: 8 [41600/50000 (83%)]\tLoss: 0.002624\n",
            "Train Epoch: 8 [42400/50000 (85%)]\tLoss: 0.018076\n",
            "Train Epoch: 8 [43200/50000 (86%)]\tLoss: 0.031541\n",
            "Train Epoch: 8 [44000/50000 (88%)]\tLoss: 0.070570\n",
            "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.029303\n",
            "Train Epoch: 8 [45600/50000 (91%)]\tLoss: 0.005963\n",
            "Train Epoch: 8 [46400/50000 (93%)]\tLoss: 0.004707\n",
            "Train Epoch: 8 [47200/50000 (94%)]\tLoss: 0.049595\n",
            "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.015070\n",
            "Train Epoch: 8 [48800/50000 (98%)]\tLoss: 0.162555\n",
            "Train Epoch: 8 [49600/50000 (99%)]\tLoss: 0.002712\n",
            "\n",
            "Validation set: Average loss: 0.0072, Accuracy: 9672/10000 (97%)\n",
            "Saved model to best_models/model_8.pth\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.015910\n",
            "Train Epoch: 9 [800/50000 (2%)]\tLoss: 0.035043\n",
            "Train Epoch: 9 [1600/50000 (3%)]\tLoss: 0.098163\n",
            "Train Epoch: 9 [2400/50000 (5%)]\tLoss: 0.010276\n",
            "Train Epoch: 9 [3200/50000 (6%)]\tLoss: 0.165681\n",
            "Train Epoch: 9 [4000/50000 (8%)]\tLoss: 0.191570\n",
            "Train Epoch: 9 [4800/50000 (10%)]\tLoss: 0.130670\n",
            "Train Epoch: 9 [5600/50000 (11%)]\tLoss: 0.013076\n",
            "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.025959\n",
            "Train Epoch: 9 [7200/50000 (14%)]\tLoss: 0.003981\n",
            "Train Epoch: 9 [8000/50000 (16%)]\tLoss: 0.002806\n",
            "Train Epoch: 9 [8800/50000 (18%)]\tLoss: 0.002304\n",
            "Train Epoch: 9 [9600/50000 (19%)]\tLoss: 0.010279\n",
            "Train Epoch: 9 [10400/50000 (21%)]\tLoss: 0.011249\n",
            "Train Epoch: 9 [11200/50000 (22%)]\tLoss: 0.013451\n",
            "Train Epoch: 9 [12000/50000 (24%)]\tLoss: 0.003304\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.051285\n",
            "Train Epoch: 9 [13600/50000 (27%)]\tLoss: 0.003906\n",
            "Train Epoch: 9 [14400/50000 (29%)]\tLoss: 0.006945\n",
            "Train Epoch: 9 [15200/50000 (30%)]\tLoss: 0.130980\n",
            "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.047399\n",
            "Train Epoch: 9 [16800/50000 (34%)]\tLoss: 0.051263\n",
            "Train Epoch: 9 [17600/50000 (35%)]\tLoss: 0.012029\n",
            "Train Epoch: 9 [18400/50000 (37%)]\tLoss: 0.006444\n",
            "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.016716\n",
            "Train Epoch: 9 [20000/50000 (40%)]\tLoss: 0.036826\n",
            "Train Epoch: 9 [20800/50000 (42%)]\tLoss: 0.195882\n",
            "Train Epoch: 9 [21600/50000 (43%)]\tLoss: 0.009785\n",
            "Train Epoch: 9 [22400/50000 (45%)]\tLoss: 0.080114\n",
            "Train Epoch: 9 [23200/50000 (46%)]\tLoss: 0.152127\n",
            "Train Epoch: 9 [24000/50000 (48%)]\tLoss: 0.019302\n",
            "Train Epoch: 9 [24800/50000 (50%)]\tLoss: 0.070224\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.003482\n",
            "Train Epoch: 9 [26400/50000 (53%)]\tLoss: 0.050555\n",
            "Train Epoch: 9 [27200/50000 (54%)]\tLoss: 0.001718\n",
            "Train Epoch: 9 [28000/50000 (56%)]\tLoss: 0.032139\n",
            "Train Epoch: 9 [28800/50000 (58%)]\tLoss: 0.010963\n",
            "Train Epoch: 9 [29600/50000 (59%)]\tLoss: 0.049537\n",
            "Train Epoch: 9 [30400/50000 (61%)]\tLoss: 0.061517\n",
            "Train Epoch: 9 [31200/50000 (62%)]\tLoss: 0.018950\n",
            "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.008117\n",
            "Train Epoch: 9 [32800/50000 (66%)]\tLoss: 0.016530\n",
            "Train Epoch: 9 [33600/50000 (67%)]\tLoss: 0.027372\n",
            "Train Epoch: 9 [34400/50000 (69%)]\tLoss: 0.019414\n",
            "Train Epoch: 9 [35200/50000 (70%)]\tLoss: 0.026600\n",
            "Train Epoch: 9 [36000/50000 (72%)]\tLoss: 0.001619\n",
            "Train Epoch: 9 [36800/50000 (74%)]\tLoss: 0.006264\n",
            "Train Epoch: 9 [37600/50000 (75%)]\tLoss: 0.001838\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.090491\n",
            "Train Epoch: 9 [39200/50000 (78%)]\tLoss: 0.000989\n",
            "Train Epoch: 9 [40000/50000 (80%)]\tLoss: 0.024903\n",
            "Train Epoch: 9 [40800/50000 (82%)]\tLoss: 0.023910\n",
            "Train Epoch: 9 [41600/50000 (83%)]\tLoss: 0.001406\n",
            "Train Epoch: 9 [42400/50000 (85%)]\tLoss: 0.021629\n",
            "Train Epoch: 9 [43200/50000 (86%)]\tLoss: 0.130418\n",
            "Train Epoch: 9 [44000/50000 (88%)]\tLoss: 0.058527\n",
            "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.516582\n",
            "Train Epoch: 9 [45600/50000 (91%)]\tLoss: 0.003537\n",
            "Train Epoch: 9 [46400/50000 (93%)]\tLoss: 0.030462\n",
            "Train Epoch: 9 [47200/50000 (94%)]\tLoss: 0.087735\n",
            "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.005118\n",
            "Train Epoch: 9 [48800/50000 (98%)]\tLoss: 0.006924\n",
            "Train Epoch: 9 [49600/50000 (99%)]\tLoss: 0.000982\n",
            "\n",
            "Validation set: Average loss: 0.0067, Accuracy: 9681/10000 (97%)\n",
            "Saved model to best_models/model_9.pth\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.002099\n",
            "Train Epoch: 10 [800/50000 (2%)]\tLoss: 0.026157\n",
            "Train Epoch: 10 [1600/50000 (3%)]\tLoss: 0.003939\n",
            "Train Epoch: 10 [2400/50000 (5%)]\tLoss: 0.035860\n",
            "Train Epoch: 10 [3200/50000 (6%)]\tLoss: 0.007652\n",
            "Train Epoch: 10 [4000/50000 (8%)]\tLoss: 0.000982\n",
            "Train Epoch: 10 [4800/50000 (10%)]\tLoss: 0.009399\n",
            "Train Epoch: 10 [5600/50000 (11%)]\tLoss: 0.015273\n",
            "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.159028\n",
            "Train Epoch: 10 [7200/50000 (14%)]\tLoss: 0.012863\n",
            "Train Epoch: 10 [8000/50000 (16%)]\tLoss: 0.090241\n",
            "Train Epoch: 10 [8800/50000 (18%)]\tLoss: 0.090602\n",
            "Train Epoch: 10 [9600/50000 (19%)]\tLoss: 0.000951\n",
            "Train Epoch: 10 [10400/50000 (21%)]\tLoss: 0.015613\n",
            "Train Epoch: 10 [11200/50000 (22%)]\tLoss: 0.004640\n",
            "Train Epoch: 10 [12000/50000 (24%)]\tLoss: 0.044123\n",
            "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.062021\n",
            "Train Epoch: 10 [13600/50000 (27%)]\tLoss: 0.000670\n",
            "Train Epoch: 10 [14400/50000 (29%)]\tLoss: 0.443317\n",
            "Train Epoch: 10 [15200/50000 (30%)]\tLoss: 0.000634\n",
            "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 0.095085\n",
            "Train Epoch: 10 [16800/50000 (34%)]\tLoss: 0.000678\n",
            "Train Epoch: 10 [17600/50000 (35%)]\tLoss: 0.075045\n",
            "Train Epoch: 10 [18400/50000 (37%)]\tLoss: 0.163076\n",
            "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.473561\n",
            "Train Epoch: 10 [20000/50000 (40%)]\tLoss: 0.018878\n",
            "Train Epoch: 10 [20800/50000 (42%)]\tLoss: 0.006025\n",
            "Train Epoch: 10 [21600/50000 (43%)]\tLoss: 0.178621\n",
            "Train Epoch: 10 [22400/50000 (45%)]\tLoss: 0.052834\n",
            "Train Epoch: 10 [23200/50000 (46%)]\tLoss: 0.278100\n",
            "Train Epoch: 10 [24000/50000 (48%)]\tLoss: 0.001767\n",
            "Train Epoch: 10 [24800/50000 (50%)]\tLoss: 0.008627\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.025989\n",
            "Train Epoch: 10 [26400/50000 (53%)]\tLoss: 0.177157\n",
            "Train Epoch: 10 [27200/50000 (54%)]\tLoss: 0.001062\n",
            "Train Epoch: 10 [28000/50000 (56%)]\tLoss: 0.049908\n",
            "Train Epoch: 10 [28800/50000 (58%)]\tLoss: 0.009150\n",
            "Train Epoch: 10 [29600/50000 (59%)]\tLoss: 0.060595\n",
            "Train Epoch: 10 [30400/50000 (61%)]\tLoss: 0.179853\n",
            "Train Epoch: 10 [31200/50000 (62%)]\tLoss: 0.043739\n",
            "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.005618\n",
            "Train Epoch: 10 [32800/50000 (66%)]\tLoss: 0.067348\n",
            "Train Epoch: 10 [33600/50000 (67%)]\tLoss: 0.001075\n",
            "Train Epoch: 10 [34400/50000 (69%)]\tLoss: 0.000524\n",
            "Train Epoch: 10 [35200/50000 (70%)]\tLoss: 0.027709\n",
            "Train Epoch: 10 [36000/50000 (72%)]\tLoss: 0.005833\n",
            "Train Epoch: 10 [36800/50000 (74%)]\tLoss: 0.063405\n",
            "Train Epoch: 10 [37600/50000 (75%)]\tLoss: 0.032349\n",
            "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.133824\n",
            "Train Epoch: 10 [39200/50000 (78%)]\tLoss: 0.067818\n",
            "Train Epoch: 10 [40000/50000 (80%)]\tLoss: 0.005914\n",
            "Train Epoch: 10 [40800/50000 (82%)]\tLoss: 0.020635\n",
            "Train Epoch: 10 [41600/50000 (83%)]\tLoss: 0.001124\n",
            "Train Epoch: 10 [42400/50000 (85%)]\tLoss: 0.144106\n",
            "Train Epoch: 10 [43200/50000 (86%)]\tLoss: 0.000747\n",
            "Train Epoch: 10 [44000/50000 (88%)]\tLoss: 0.012152\n",
            "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.015874\n",
            "Train Epoch: 10 [45600/50000 (91%)]\tLoss: 0.001566\n",
            "Train Epoch: 10 [46400/50000 (93%)]\tLoss: 0.074507\n",
            "Train Epoch: 10 [47200/50000 (94%)]\tLoss: 0.007172\n",
            "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 0.329047\n",
            "Train Epoch: 10 [48800/50000 (98%)]\tLoss: 0.011707\n",
            "Train Epoch: 10 [49600/50000 (99%)]\tLoss: 0.160388\n",
            "\n",
            "Validation set: Average loss: 0.0070, Accuracy: 9680/10000 (97%)\n",
            "Saved model to best_models/model_10.pth\n",
            "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.155737\n",
            "Train Epoch: 11 [800/50000 (2%)]\tLoss: 0.013136\n",
            "Train Epoch: 11 [1600/50000 (3%)]\tLoss: 0.007826\n",
            "Train Epoch: 11 [2400/50000 (5%)]\tLoss: 0.031539\n",
            "Train Epoch: 11 [3200/50000 (6%)]\tLoss: 0.005596\n",
            "Train Epoch: 11 [4000/50000 (8%)]\tLoss: 0.109931\n",
            "Train Epoch: 11 [4800/50000 (10%)]\tLoss: 0.002598\n",
            "Train Epoch: 11 [5600/50000 (11%)]\tLoss: 0.027452\n",
            "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 0.204156\n",
            "Train Epoch: 11 [7200/50000 (14%)]\tLoss: 0.038713\n",
            "Train Epoch: 11 [8000/50000 (16%)]\tLoss: 0.020147\n",
            "Train Epoch: 11 [8800/50000 (18%)]\tLoss: 0.108930\n",
            "Train Epoch: 11 [9600/50000 (19%)]\tLoss: 0.033322\n",
            "Train Epoch: 11 [10400/50000 (21%)]\tLoss: 0.002343\n",
            "Train Epoch: 11 [11200/50000 (22%)]\tLoss: 0.036213\n",
            "Train Epoch: 11 [12000/50000 (24%)]\tLoss: 0.016562\n",
            "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.041074\n",
            "Train Epoch: 11 [13600/50000 (27%)]\tLoss: 0.003423\n",
            "Train Epoch: 11 [14400/50000 (29%)]\tLoss: 0.074464\n",
            "Train Epoch: 11 [15200/50000 (30%)]\tLoss: 0.084876\n",
            "Train Epoch: 11 [16000/50000 (32%)]\tLoss: 0.094423\n",
            "Train Epoch: 11 [16800/50000 (34%)]\tLoss: 0.030805\n",
            "Train Epoch: 11 [17600/50000 (35%)]\tLoss: 0.009574\n",
            "Train Epoch: 11 [18400/50000 (37%)]\tLoss: 0.019244\n",
            "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 0.012007\n",
            "Train Epoch: 11 [20000/50000 (40%)]\tLoss: 0.114098\n",
            "Train Epoch: 11 [20800/50000 (42%)]\tLoss: 0.026722\n",
            "Train Epoch: 11 [21600/50000 (43%)]\tLoss: 0.104785\n",
            "Train Epoch: 11 [22400/50000 (45%)]\tLoss: 0.023000\n",
            "Train Epoch: 11 [23200/50000 (46%)]\tLoss: 0.011035\n",
            "Train Epoch: 11 [24000/50000 (48%)]\tLoss: 0.021831\n",
            "Train Epoch: 11 [24800/50000 (50%)]\tLoss: 0.013926\n",
            "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.006596\n",
            "Train Epoch: 11 [26400/50000 (53%)]\tLoss: 0.002498\n",
            "Train Epoch: 11 [27200/50000 (54%)]\tLoss: 0.012279\n",
            "Train Epoch: 11 [28000/50000 (56%)]\tLoss: 0.033684\n",
            "Train Epoch: 11 [28800/50000 (58%)]\tLoss: 0.003434\n",
            "Train Epoch: 11 [29600/50000 (59%)]\tLoss: 0.007216\n",
            "Train Epoch: 11 [30400/50000 (61%)]\tLoss: 0.115844\n",
            "Train Epoch: 11 [31200/50000 (62%)]\tLoss: 0.006546\n",
            "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.001934\n",
            "Train Epoch: 11 [32800/50000 (66%)]\tLoss: 0.053212\n",
            "Train Epoch: 11 [33600/50000 (67%)]\tLoss: 0.000686\n",
            "Train Epoch: 11 [34400/50000 (69%)]\tLoss: 0.000610\n",
            "Train Epoch: 11 [35200/50000 (70%)]\tLoss: 0.005200\n",
            "Train Epoch: 11 [36000/50000 (72%)]\tLoss: 0.002459\n",
            "Train Epoch: 11 [36800/50000 (74%)]\tLoss: 0.377857\n",
            "Train Epoch: 11 [37600/50000 (75%)]\tLoss: 0.022325\n",
            "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.067416\n",
            "Train Epoch: 11 [39200/50000 (78%)]\tLoss: 0.434076\n",
            "Train Epoch: 11 [40000/50000 (80%)]\tLoss: 0.177396\n",
            "Train Epoch: 11 [40800/50000 (82%)]\tLoss: 0.017854\n",
            "Train Epoch: 11 [41600/50000 (83%)]\tLoss: 0.048468\n",
            "Train Epoch: 11 [42400/50000 (85%)]\tLoss: 0.019872\n",
            "Train Epoch: 11 [43200/50000 (86%)]\tLoss: 0.006341\n",
            "Train Epoch: 11 [44000/50000 (88%)]\tLoss: 0.013728\n",
            "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 0.055369\n",
            "Train Epoch: 11 [45600/50000 (91%)]\tLoss: 0.005102\n",
            "Train Epoch: 11 [46400/50000 (93%)]\tLoss: 0.002090\n",
            "Train Epoch: 11 [47200/50000 (94%)]\tLoss: 0.069748\n",
            "Train Epoch: 11 [48000/50000 (96%)]\tLoss: 0.007690\n",
            "Train Epoch: 11 [48800/50000 (98%)]\tLoss: 0.000269\n",
            "Train Epoch: 11 [49600/50000 (99%)]\tLoss: 0.000461\n",
            "\n",
            "Validation set: Average loss: 0.0057, Accuracy: 9727/10000 (97%)\n",
            "Saved model to best_models/model_11.pth\n",
            "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.009850\n",
            "Train Epoch: 12 [800/50000 (2%)]\tLoss: 0.004756\n",
            "Train Epoch: 12 [1600/50000 (3%)]\tLoss: 0.004299\n",
            "Train Epoch: 12 [2400/50000 (5%)]\tLoss: 0.006360\n",
            "Train Epoch: 12 [3200/50000 (6%)]\tLoss: 0.036849\n",
            "Train Epoch: 12 [4000/50000 (8%)]\tLoss: 0.001641\n",
            "Train Epoch: 12 [4800/50000 (10%)]\tLoss: 0.001397\n",
            "Train Epoch: 12 [5600/50000 (11%)]\tLoss: 0.003300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7b5e9e9c1235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#initialise the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#do the training of the epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#and the validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'best_models'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7b5e9e9c1235>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#We decide to use cross entropy loss for classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#do the backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#We print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgQVAmoF4QpQ",
        "colab_type": "text"
      },
      "source": [
        "# Or load the weight I have saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6CVIkGd43Nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_path = \"/content/best_models/model_11.pth\" #put the pass of the weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kDf-_RA4U59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f89e863d-707e-4d6b-d3be-8ef12ae97ed7"
      },
      "source": [
        "model = models.resnet152(pretrained=False)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features,10)\n",
        "\n",
        "state_dict = torch.load(weight_path)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "if use_cuda:\n",
        "    print('Using GPU')\n",
        "    model.cuda()\n",
        "else:\n",
        "    print('Using CPU')\n",
        "        \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9CZfKVh5b-C",
        "colab_type": "text"
      },
      "source": [
        "# Quantitative results ( accuracy )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IjTcjI25qbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e66267ae-9f44-488f-d256-04077178a037"
      },
      "source": [
        "validation() "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation set: Average loss: 0.0057, Accuracy: 9727/10000 (97%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXBUiygq5u5g",
        "colab_type": "text"
      },
      "source": [
        "# Qualitative results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8s9TsEW6PVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    img = img.cpu()\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7DE06ep5xKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "24145265-7369-43ca-ef8b-1d02fee6a496"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "dataiter = iter(val_loader)\n",
        "images, labels = dataiter.next()\n",
        "if use_cuda:\n",
        "  images, labels = images.cuda(), labels.cuda()\n",
        "imshow(torchvision.utils.make_grid(images)) #We show images from test dataset\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(16))) #avec leurs vrai labels\n",
        "\n",
        "#et on affiche nos predictions\n",
        "outputs = model(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(16)))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAB3CAYAAADmfjD5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:    cat  ship  ship plane  frog  frog   car  frog   cat   car plane truck   dog horse truck  ship\n",
            "Predicted:    cat  ship  ship plane  frog  frog   car  frog   cat   car plane truck   dog horse truck  ship\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7BO-Eq8776-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}